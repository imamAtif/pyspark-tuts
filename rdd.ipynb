{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/21 07:26:56 WARN Utils: Your hostname, vivoBook resolves to a loopback address: 127.0.1.1; using 192.168.1.4 instead (on interface wlan0)\n",
      "24/03/21 07:26:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/21 07:26:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# Create a Spark configuration\n",
    "conf = SparkConf().setAppName(\"RDDAggregateExample\").setMaster(\"local[*]\")\n",
    "\n",
    "# Create a Spark context\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an RDD of integers\n",
    "numbers_rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "# print rdd value\n",
    "numbers_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial value for aggregation\n",
    "initial_value = (0, 0)  # (sum, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation function\n",
    "def seq_op(acc, value):\n",
    "    sum_, count = acc\n",
    "    return sum_ + value, count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the combining function\n",
    "def comb_op(acc1, acc2):\n",
    "    sum1, count1 = acc1\n",
    "    sum2, count2 = acc2\n",
    "    return sum1 + sum2, count1 + count2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                        (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 15, Count: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use the aggregate function to compute sum and count\n",
    "result = numbers_rdd.aggregate(initial_value, seq_op, comb_op)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sum: {result[0]}, Count: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 999\n",
      "sum: 499500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Persist this RDD with the default storage level (MEMORY_ONLY).\n",
    "# step-1: create a rdd\n",
    "numbers_rdd= sc.parallelize(range(1,1000))\n",
    "print(numbers_rdd.collect())\n",
    "# cache the RDD in memory\n",
    "numbers_rdd.cache()\n",
    "# perform some operation in RDD (e.g count and Sum)\n",
    "count = numbers_rdd.count()\n",
    "total_sum = numbers_rdd.reduce(lambda x,y:x+y)\n",
    "print(f\"count: {count}\")\n",
    "print(f\"sum: {total_sum}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Memory Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "# check if the above rdd is cached ?\n",
    "print(numbers_rdd.is_cached)\n",
    "# see where this rdd is cached, whether in memory or disk?\n",
    "print(numbers_rdd.getStorageLevel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coalesce()\n",
    " - `coalesce` method on an RDD to  only **reduce**  the number of partitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of partition 4\n",
      "no of partition after coalesce 2\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# lets create a rdd with 4 partitions\n",
    "original_rdd = sc.parallelize([1,2,3,4,5,6,7,8],4)\n",
    "# check the no of partition\n",
    "print(\"number of partition\",original_rdd.getNumPartitions())\n",
    "# coalesce the rdd into 2 partitions\n",
    "coalesce_rdd = original_rdd.coalesce(2)\n",
    "# check the number of partition after coalesce\n",
    "print(\"no of partition after coalesce\",coalesce_rdd.getNumPartitions()) \n",
    "# collect and print rdd\n",
    "print(coalesce_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repartition()\n",
    "- `repartiton can be used to either increase or decrease the number of partitions in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions before repartition: 4\n",
      "new no of partitions 6\n",
      "no of partition 2\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with 4 partitions\n",
    "original_rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8], 4)\n",
    "# Get the number of partitions in the original RDD\n",
    "num_partitions_before = original_rdd.getNumPartitions()\n",
    "print(\"Number of partitions before repartition:\", num_partitions_before)\n",
    "# lets increase the no of partiton to 6\n",
    "increased_partition_rdd = original_rdd.repartition(6)\n",
    "# check the no of partition in new RDD.\n",
    "print(\"new no of partitions\",increased_partition_rdd.getNumPartitions())\n",
    "# lets decrease the no of partiton to 2\n",
    "decreased_no_partitions = original_rdd.repartition(2)\n",
    "print(\"no of partition\",decreased_no_partitions.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count()\n",
    "- it is used to count the no of elements in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of elements in the RDD: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some elements\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# Count the number of elements in the RDD using count()\n",
    "element_count = rdd.count()\n",
    "# Print the total count of elements in the RDD\n",
    "print(\"Total count of elements in the RDD:\", element_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countByKey()\n",
    "- the countByKey() method is used specifically on an RDD of key-value pairs to count the occurrences of each unique key in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 2, 'banana': 1, 'cherry': 1, 'orange': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD of key-value pairs\n",
    "rdd = sc.parallelize([( 'apple',1), ( 'banana',1), ( 'cherry',1), ( 'apple',2), ( 'orange',4)])\n",
    "# Count the occurrences of each key in the RDD using countByKey()\n",
    "key_counts = rdd.countByKey()\n",
    "# print the count dict\n",
    "print(dict(key_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countByValue()\n",
    "-  countByValue() method is used to count the occurrences of each unique element in an RDD. This method is typically applied to RDDs containing non-key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 3, 2: 3, 3: 1, 4: 1, 5: 1})\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some elements\n",
    "rdd = sc.parallelize([1, 2, 3, 2, 1, 4, 5, 2, 1])\n",
    "\n",
    "# Count the occurrences of each unique element in the RDD using countByValue()\n",
    "element_counts = rdd.countByValue()\n",
    "# Print the element counts\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distinct()\n",
    "- returns a new rdd with distinct elements from original rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 2, 1, 4, 5, 2, 1]\n",
      "Distinct elements in the RDD:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:==========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an RDD with duplicate elements\n",
    "rdd = sc.parallelize([1, 2, 3, 2, 1, 4, 5, 2, 1])\n",
    "# print the original rdd\n",
    "print(rdd.collect())\n",
    "\n",
    "# Get the distinct elements from the RDD using distinct()\n",
    "distinct_rdd = rdd.distinct()\n",
    "\n",
    "# Collect and print the distinct elements\n",
    "print(\"Distinct elements in the RDD:\")\n",
    "print(distinct_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter()\n",
    "- it is used to create new RDD containing the elements that satisfy the condition . you can relate it to `where` clause fo SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Filtered elements in the RDD (even numbers):\n",
      "[2, 4, 6, 8, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some elements\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# print original rdd\n",
    "print(rdd.collect())\n",
    "# Filter the RDD to keep only even numbers\n",
    "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "\n",
    "# Collect and print the filtered elements\n",
    "print(\"Filtered elements in the RDD (even numbers):\")\n",
    "print(filtered_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first()\n",
    " - returns the first element in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 45, 12, 9, 34]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# create an rdd with some elements\n",
    "rdd = sc.parallelize([11,45,12,9,34])\n",
    "# print the complete rdd\n",
    "print(rdd.collect())\n",
    "# print the first element of the rdd\n",
    "print(rdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map()\n",
    " - it is used to transform each element in an rdd using a specified function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "Squared elements in the RDD:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some elements\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "# print the original rdd\n",
    "print(rdd.collect())\n",
    "\n",
    "# Map each element to its square using map()\n",
    "squared_rdd = rdd.map(lambda x: x * x)\n",
    "# Collect and print the transformed elements\n",
    "print(\"Squared elements in the RDD:\")\n",
    "print(squared_rdd.collect())\n",
    "\n",
    "# this can be done using function too instead of lambda\n",
    "def sq_ele(x):\n",
    "    return x*x\n",
    "squared_rdd_by_func = rdd.map(sq_ele)\n",
    "print(squared_rdd_by_func.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flatmap\n",
    "- it maps each element in rdd using a specified function. the result is a flattened rdd containing all the transformed elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped elements (list of words) using map():\n",
      "[['Hello', 'world'], ['Good', 'morning'], ['How', 'are', 'you']]\n",
      "\n",
      "Flattened elements (individual words) using flatMap():\n",
      "['Hello', 'world', 'Good', 'morning', 'How', 'are', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some words in sentences\n",
    "rdd = sc.parallelize([\"Hello world\", \"Good morning\", \"How are you\"])\n",
    "\n",
    "# Apply map() to split each sentence into words\n",
    "mapped_rdd = rdd.map(lambda line: line.split())\n",
    "\n",
    "# Apply flatMap() to split each sentence into words and flatten the result\n",
    "flat_mapped_rdd = rdd.flatMap(lambda line: line.split())\n",
    "\n",
    "# Collect and print the results\n",
    "print(\"Mapped elements (list of words) using map():\")\n",
    "print(mapped_rdd.collect())\n",
    "\n",
    "print(\"\\nFlattened elements (individual words) using flatMap():\")\n",
    "print(flat_mapped_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# foreach()\n",
    "- applies a function to each element of the RDD\n",
    "- unlike `map()` and `flatmap()` (bot of these are transformations), `foreach()` is an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Element: 5\n",
      "Element: 2\n",
      "Element: 4\n",
      "Element: 1\n",
      "Element: 3==============================================>         (10 + 2) / 12]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some elements\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# Define a function to print each element\n",
    "def print_element(element):\n",
    "    print(\"Element:\", element)\n",
    "\n",
    "# Apply foreach() to print each element\n",
    "rdd.foreach(print_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupBy()\n",
    "- returns an RDD of grouped items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped elements in the RDD by length:\n",
      "Length: 3, Grouped Elements: ['Tom']\n",
      "Length: 4, Grouped Elements: ['John', 'John']\n",
      "Length: 5, Grouped Elements: ['Jimmy', 'Jacky', 'Jimmy', 'Jimmy']\n",
      "Length: 6, Grouped Elements: ['Lenevo']\n",
      "Length: 7, Grouped Elements: ['Anvisha']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create an RDD\n",
    "rdd = sc.parallelize([\"Tom\", \"Lenevo\", \"Anvisha\",\n",
    "    \"John\", \"Jimmy\", \"Jacky\",\n",
    "    \"John\", \"Jimmy\", \"Jimmy\"])\n",
    "# Using groupBy transformation to group elements based on their length\n",
    "group_rdd = rdd.groupBy( lambda x: len(x))\n",
    "# Iterate through the grouped RDD and print the key and grouped elements\n",
    "print(\"Grouped elements in the RDD by length:\")\n",
    "for key, group in group_rdd.collect():\n",
    "    print(f\"Length: {key}, Grouped Elements: {list(group)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupByKey()\n",
    "- used to group elements of an RDD by a key. It is similar to the groupBy() method, but specifically designed for RDDs containing key-value pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 1), ('A', 3), ('B', 4), ('B', 2), ('C', 5)]\n",
      "B [4, 2]\n",
      "C [5]\n",
      "A [1, 3]\n"
     ]
    }
   ],
   "source": [
    "# create an key-value rdd\n",
    "rdd = sc.parallelize([(\"A\",1),(\"A\",3),(\"B\",4),(\"B\",2),(\"C\",5)])\n",
    "print(rdd.collect())\n",
    "# lets group it by key\n",
    "grouped_by_key = rdd.groupByKey()\n",
    "# iterate through rdd and print the key and grouped elements\n",
    "for key,group in grouped_by_key.collect():\n",
    "    print(key,list(group))\n",
    "# print(rdd.groupByKey().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# persist()\n",
    "- Set this RDD’s storage level to persist its values across operations after the first time it is computed. This can only be used to assign a new storage level if the RDD does not have a storage level set yet. If no storage level is specified defaults to (MEMORY_ONLY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Memory Serialized 1x Replicated\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# create a new rdd\n",
    "rdd = sc.parallelize([\"a\",\"b\",\"c\"])\n",
    "# persist it\n",
    "rdd.persist()\n",
    "# check if it is cached\n",
    "print(rdd.is_cached)\n",
    "# print the storage level of the rdd\n",
    "print(rdd.getStorageLevel())\n",
    "\n",
    "# lets unpersis it\n",
    "rdd.unpersist()\n",
    "print(rdd.is_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cache()\n",
    "- cache is shorthand for rdd.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduceByKey()\n",
    "-  merge the values for each key using  an associative and cumulative redue fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced RDD:\n",
      "[(1, 40), (2, 70), (3, 40)]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with key-value pairs\n",
    "rdd = sc.parallelize([(1, 10), (2, 20), (1, 30), (3, 40), (2, 50)])\n",
    "\n",
    "# Reduce values by key using reduceByKey()\n",
    "reduced_rdd = rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Collect and print the reduced RDD\n",
    "print(\"Reduced RDD:\")\n",
    "print(reduced_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textFile()\n",
    "- reads a textfile to create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenati']\n"
     ]
    }
   ],
   "source": [
    "# lets read a texfile to create an RDD\n",
    "rdd = sc.textFile('sample_rdd_text.txt')\n",
    "# print the content of rdd\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saveAsTextFile()\n",
    "- saves the rdd to texfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD with some data\n",
    "data = [\"Hello\", \"World\", \"Spark\", \"is\", \"awesome\"]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# lets save the rdd to a textfile\n",
    "rdd.coalesce(1).saveAsTextFile(\"rdd_as_textfile\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sortBy()\n",
    "- sorts the RDD by given keyFunc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'apple'), (3, 'orange'), (2, 'banana'), (4, 'grape')]\n",
      "Sorted RDD (Ascending):\n",
      "[(1, 'apple'), (2, 'banana'), (3, 'orange'), (4, 'grape')]\n",
      "\n",
      "Sorted RDD (Descending):\n",
      "[(3, 'orange'), (4, 'grape'), (2, 'banana'), (1, 'apple')]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with some data\n",
    "data = [(1, 'apple'), (3, 'orange'), (2, 'banana'), (4, 'grape')]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "print(rdd.collect())\n",
    "# Sort the RDD by the first element of each tuple (ascending order)\n",
    "sorted_rdd_asc = rdd.sortBy(lambda x: x[0])\n",
    "\n",
    "# Sort the RDD by the second element of each tuple (descending order)\n",
    "sorted_rdd_desc = rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Collect and print the sorted RDDs\n",
    "print(\"Sorted RDD (Ascending):\")\n",
    "print(sorted_rdd_asc.collect())\n",
    "\n",
    "print(\"\\nSorted RDD (Descending):\")\n",
    "print(sorted_rdd_desc.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sortByKey()\n",
    "- used to sort an RDD containing key-value pairs by their keys. This method is specifically designed for RDDs where each element is a tuple or pair, with the first element of the tuple being the key and the second element being the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_rdd [(3, 'orange'), (1, 'apple'), (2, 'banana'), (4, 'grape')]\n",
      "Sorted  ascending RDD by key:\n",
      "[(1, 'apple'), (2, 'banana'), (3, 'orange'), (4, 'grape')]\n",
      "Sorted  ascending RDD by key:\n",
      "[(4, 'grape'), (3, 'orange'), (2, 'banana'), (1, 'apple')]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD with key-value pairs\n",
    "data = [(3, 'orange'), (1, 'apple'), (2, 'banana'), (4, 'grape')]\n",
    "rdd = sc.parallelize(data)\n",
    "print(\"original_rdd\",rdd.collect())\n",
    "\n",
    "# Sort the RDD by keys using sortByKey()\n",
    "sorted_rdd = rdd.sortByKey(ascending=True)\n",
    "\n",
    "# Collect and print the sorted RDD\n",
    "print(\"Sorted  ascending RDD by key:\")\n",
    "print(sorted_rdd.collect())\n",
    "#  Sort the RDD by keys using sortByKey()\n",
    "sorted_rdd = rdd.sortByKey(ascending=False)\n",
    "print(\"Sorted  ascending RDD by key:\")\n",
    "print(sorted_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
